## Best Docs to Date
- [API usage overview](https://github.com/openstax/napkin-notes/blob/master/kevin/160921_biglearnApis/api_usage.md)
- [BL deployment overview](https://github.com/openstax/napkin-notes/blob/master/kevin/BiglearnArchitectureDeployment.pdf)
- [Drew's presentation](https://docs.google.com/presentation/d/1qoPqBLD4XqOsIfcM6aJH7IaDQRsxxuA6QBLy4GIZy7w/edit#slide=id.p)
- [Kevin's SPARFA Guide](https://github.com/openstax/sparfa-sandbox/blob/master/klb_sparfa_guide/sparfa_guide.pdf)
- [Kevin's Autoscaling Notes](https://docs.google.com/document/d/1bmn2xYBURE90fiZrdNG5CN28vEBCPJbKukDTbUqntZ4/edit)
- [Kevin's Biglearn Autoscaling Big Picure](https://docs.google.com/document/d/1JGcHIzmHDaDFlQvznzYgsWHuXBRis9qvtwF6pwaYVfQ/edit)

## Feature Flags/Toggles Napkin Note

Feature flags, feature toggles, and the release process
came up in coversation a few times this week.
So I wrote down a terminology 
[reference](https://github.com/openstax/napkin-notes/blob/master/kevin/180329_flagsTogglesDeployment.md)
in the hopes of avoiding miscommunication
between devs, managers, etc.

## Nested Stack Templates

I fixed my deployment script.
I folded in the 
[AWS ruby SDK](https://aws.amazon.com/sdk-for-ruby/)
(which is really great, BTW)
to replace calls to the AWS CLI,
which were getting unweildy.

## Autoscaling Healthchecks

I did a quick test of my AWS healthcheck setup.

| Time (sec)    | Event |
| ------------- |:-------------|
| 0       | web server is killed |
| 30      | ELB finished redirecting traffic away from unhealthy server |
| 180     | new server serving requests |

This is actually pretty good,
since it usually takes AWS upwards of 5 mins
to detect problems by other means.

This test suggests
that if we want to hide (relatively rare) server failures from our end users,
we need to have our FE client code
do a few staggered retries
before giving up and displaying an error message.

Note that these types of failures
are corrected by the use of autoscaling groups,
but are not related to zero-downtime deployments or migrations.

## Autoscaling Alarms

I am very close to having more fine-grained control
over the metrics and alarm events
that trigger autoscaling events
in response to fluctuating user demand.

## Back to BL API Endpoints?

I'm getting close.

I need to finish the alarm work.
Then I want to create a skeleton application
(which is essentially one BL API endpoint)
to really test my event bundling algorithm
until it breaks.

Then I will get back to folding in BL API endpoints.
